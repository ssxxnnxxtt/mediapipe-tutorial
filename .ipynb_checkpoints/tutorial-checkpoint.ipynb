{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8c13cb",
   "metadata": {},
   "source": [
    "# Mediapipe tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44088d0f",
   "metadata": {},
   "source": [
    "<img src='cover_image/mediapipe_small.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915045bc",
   "metadata": {},
   "source": [
    "## First, import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb41413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video processing\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "#Manage .csv file\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f840667",
   "metadata": {},
   "source": [
    "## Setting Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26176498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7424bac",
   "metadata": {},
   "source": [
    "## Test with the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('videos/1.MOV')\n",
    "frameTime = 1\n",
    "threshold = 0\n",
    "\n",
    "#Important value\n",
    "speed_up = 1\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        threshold += 1\n",
    "\n",
    "        showed, frame = cap.read()\n",
    "        if showed:\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img.flags.writeable = False\n",
    "\n",
    "            results = holistic.process(img)\n",
    "            \n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            img.flags.writeable = True\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            if threshold % speed_up == 0:\n",
    "                cv2.imshow('Mediapipe Feed', img)\n",
    "\n",
    "            if cv2.waitKey(frameTime) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1211c6",
   "metadata": {},
   "source": [
    "## Plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ed2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('videos/1.MOV')\n",
    "frameTime = 1\n",
    "threshold = 0\n",
    "\n",
    "#Contain axis landmark of each frame\n",
    "results_list = []\n",
    "\n",
    "#Important value\n",
    "speed_up = 4\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        threshold += 1\n",
    "\n",
    "        showed, frame = cap.read()\n",
    "        if showed:\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img.flags.writeable = False\n",
    "\n",
    "            results = holistic.process(img)\n",
    "\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            img.flags.writeable = True\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            #Working frame by frame\n",
    "            if threshold % speed_up == 0:\n",
    "                cv2.imshow('Mediapipe Feed', img)\n",
    "                results_list.append(results)\n",
    "\n",
    "            if cv2.waitKey(frameTime) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting angles of graph\n",
    "elavation = 25\n",
    "azimuth=25\n",
    "\n",
    "#Plot the each frame graph\n",
    "for i in range(len(results_list)):\n",
    "    mp_drawing.plot_landmarks(results_list[i].pose_landmarks, mp_pose.POSE_CONNECTIONS, elevation=elavation, azimuth=azimuth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611f8e3",
   "metadata": {},
   "source": [
    "## Your turn 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5cd78a",
   "metadata": {},
   "source": [
    "I want to see 2d graph, including xy, yz and xz graph. Can you help me to setting the value of rotation angles of graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d848c6f",
   "metadata": {},
   "source": [
    "### XY graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fb218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee3ca7f",
   "metadata": {},
   "source": [
    "### YZ graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f83e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1a6bc7",
   "metadata": {},
   "source": [
    "### XZ graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171438c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5520581",
   "metadata": {},
   "source": [
    "## Your turn 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5f0fa",
   "metadata": {},
   "source": [
    "It's a good if you can see the detection of bodies node. You can write data into the file. I want you write a node data to csv file. I have a hint including\n",
    "- Match your speed up (condition if threshold % speed_up == 0) and iterate the all bodies node in Mediapipe detected (How many node detected?)\n",
    "- After you iterate the all bodies node, you can get the each axis of each body node.\n",
    "- For example (you can print them.)\n",
    "    - landmarks[index_body_node].x\n",
    "    - landmarks[index_body_node].y\n",
    "    - landmarks[index_body_node].z\n",
    "- In csv file, I want the columns including clip_name, threshold_speed_up, the total of axis (x,y,z) of each body node.\n",
    "- So, how many columns in csv file?\n",
    "- You can use pandas library for help it.\n",
    "    - First, you create a blank dataframe\n",
    "    - Second, you create a column name into the column_name_list.\n",
    "    - Third, match your speed up and iterate the all bodies node.\n",
    "    - Fourth, while itereate the all bodies node, you append the all axis (x, y, z) in temp list that create before iterate bodies node.\n",
    "    - Fifth, write all your appended list in dataframe that you create first.\n",
    "    - Finally, save all data into the csv file. (It's good before you save into the csv file, you see the out put the example below.)\n",
    "\n",
    "Can you write the detection of bodis node in csv file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737efd6",
   "metadata": {},
   "source": [
    "#### Example csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd19f12",
   "metadata": {},
   "source": [
    "<img src='cover_image/csv_example.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216c2ea",
   "metadata": {},
   "source": [
    "#### The total pose node in Mediapipe detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280dc23",
   "metadata": {},
   "source": [
    "<img src='cover_image/pose_tracking_full_body_landmarks.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996fccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d5282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5525d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
